{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Game_Sentiment_Final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quaziharis/E-Commerce/blob/master/Game_Sentiment_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zokp2js6S8qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd  \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xhQBRnc9vKg",
        "colab_type": "code",
        "outputId": "9621696e-7dd4-4196-c381-ba4a70e714be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "source": [
        "!pip install nltk\n",
        "!pip install spacy\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "pd.set_option('display.max_rows', None)\n",
        "import seaborn as sns\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (46.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.6.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.21.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.38.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.18.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (1.6.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.4.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.1.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxmooFqWABoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/train.csv')\n",
        "test = pd.read_csv('/content/test.csv')\n",
        "game_overview = pd.read_csv('/content/game_overview.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Vuex0kAjGG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.merge(df,game_overview[['title','developer', 'publisher', 'tags','overview']],\n",
        "                 on='title', \n",
        "                 how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bw5YBhy1f6Qf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.merge(test,game_overview[['title','developer', 'publisher', 'tags','overview']],\n",
        "                 on='title', \n",
        "                 how='left')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4p1CfceAL8V",
        "colab_type": "code",
        "outputId": "0596ed18-caf0-459b-effb-c14c173cdd83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import spacy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize.toktok import ToktokTokenizer\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from contractions import CONTRACTION_MAP\n",
        "import unicodedata\n",
        "nlp = spacy.load('en_core_web_sm', parse=True, tag=True, entity=True)\n",
        "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
        "tokenizer = ToktokTokenizer()\n",
        "stopword_list = nltk.corpus.stopwords.words('english')\n",
        "stopword_list.remove('no')\n",
        "stopword_list.remove('not')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW50yb3xAiu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def strip_html_tags(text):\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\n",
        "    stripped_text = soup.get_text()\n",
        "    return stripped_text\n",
        "#Removing accented characters\n",
        "def remove_accented_chars(text):\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    return text\n",
        "\n",
        "#Expanding Contractions\n",
        "def expand_contractions(text, contraction_mapping=CONTRACTION_MAP):\n",
        "    \n",
        "    contractions_pattern = re.compile('({})'.format('|'.join(contraction_mapping.keys())), \n",
        "                                      flags=re.IGNORECASE|re.DOTALL)\n",
        "    def expand_match(contraction):\n",
        "        match = contraction.group(0)\n",
        "        first_char = match[0]\n",
        "        expanded_contraction = contraction_mapping.get(match)\\\n",
        "                                if contraction_mapping.get(match)\\\n",
        "                                else contraction_mapping.get(match.lower())                       \n",
        "        expanded_contraction = first_char+expanded_contraction[1:]\n",
        "        return expanded_contraction\n",
        "        \n",
        "    expanded_text = contractions_pattern.sub(expand_match, text)\n",
        "    expanded_text = re.sub(\"'\", \"\", expanded_text)\n",
        "    return expanded_text\n",
        "\n",
        "#Removing Special Characters\n",
        "def remove_special_characters(text, remove_digits=False):\n",
        "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnTvJpCkDfnE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Stemming\n",
        "def simple_stemmer(text):\n",
        "    ps = nltk.porter.PorterStemmer()\n",
        "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
        "    return text\n",
        "\n",
        "def lemmatize_text(text):\n",
        "    text = nlp(text)\n",
        "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
        "    return text\n",
        "\n",
        "#Removing Stop Words\n",
        "\n",
        "def remove_stopwords(text, is_lower_case=False):\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    tokens = [token.strip() for token in tokens]\n",
        "    if is_lower_case:\n",
        "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
        "    else:\n",
        "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
        "    filtered_text = ' '.join(filtered_tokens)    \n",
        "    return filtered_text\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1l8zMvfBcKR",
        "colab_type": "code",
        "outputId": "9c75eae7-acbc-49f3-82b2-5d1a6233d022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "  df.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>title</th>\n",
              "      <th>year</th>\n",
              "      <th>user_review</th>\n",
              "      <th>user_suggestion</th>\n",
              "      <th>developer</th>\n",
              "      <th>publisher</th>\n",
              "      <th>tags</th>\n",
              "      <th>overview</th>\n",
              "      <th>full_text</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Spooky's Jump Scare Mansion</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>I'm scared and hearing creepy voices.  So I'll...</td>\n",
              "      <td>1</td>\n",
              "      <td>Lag Studios</td>\n",
              "      <td>Lag Studios</td>\n",
              "      <td>['Horror', 'Free to Play', 'Cute', 'First-Pers...</td>\n",
              "      <td>Can you survive 1000 rooms of cute terror? Or ...</td>\n",
              "      <td>Spooky's Jump Scare Mansion. I'm scared and he...</td>\n",
              "      <td>spookys jump scare mansion scared hear creepy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Spooky's Jump Scare Mansion</td>\n",
              "      <td>2016.0</td>\n",
              "      <td>Best game, more better than Sam Pepper's YouTu...</td>\n",
              "      <td>1</td>\n",
              "      <td>Lag Studios</td>\n",
              "      <td>Lag Studios</td>\n",
              "      <td>['Horror', 'Free to Play', 'Cute', 'First-Pers...</td>\n",
              "      <td>Can you survive 1000 rooms of cute terror? Or ...</td>\n",
              "      <td>Spooky's Jump Scare Mansion. Best game, more b...</td>\n",
              "      <td>spookys jump scare mansion good game well sam ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   review_id  ...                                         clean_text\n",
              "0          1  ...  spookys jump scare mansion scared hear creepy ...\n",
              "1          2  ...  spookys jump scare mansion good game well sam ...\n",
              "\n",
              "[2 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJHughkJEV4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# combining headline and article text\n",
        "df['full_text'] = df[\"title\"].map(str)+ '. ' + df[\"user_review\"]+ '. ' + df[\"overview\"]+ '. ' + df[\"tags\"].map(str)+ '. ' +df['publisher']+'. '+df['developer']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fk3SOwSigCc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test['full_text'] = test[\"title\"].map(str)+ '. ' + test[\"user_review\"]+ '. ' + test[\"overview\"]+ '. ' + test[\"tags\"].map(str)+ '. ' +test['publisher']+'. '+test['developer']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwy9-fyYFETd",
        "colab_type": "code",
        "outputId": "a9a85a3b-f157-454e-d1dd-855b7a75164e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "def normalize_corpus(corpus, html_stripping=True, contraction_expansion=True,\n",
        "                     accented_char_removal=True, text_lower_case=True, \n",
        "                     text_lemmatization=True, special_char_removal=True, \n",
        "                     stopword_removal=True, remove_digits=True):\n",
        "    \n",
        "    normalized_corpus = []\n",
        "    # normalize each document in the corpus\n",
        "    for doc in corpus:\n",
        "        # strip HTML\n",
        "        if html_stripping:\n",
        "            doc = strip_html_tags(doc)\n",
        "        # remove accented characters\n",
        "        if accented_char_removal:\n",
        "            doc = remove_accented_chars(doc)\n",
        "        # expand contractions    \n",
        "        if contraction_expansion:\n",
        "            doc = expand_contractions(doc)\n",
        "        # lowercase the text    \n",
        "        if text_lower_case:\n",
        "            doc = doc.lower()\n",
        "        # remove extra newlines\n",
        "        doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
        "        # lemmatize text\n",
        "        if text_lemmatization:\n",
        "            doc = lemmatize_text(doc)\n",
        "        # remove special characters and\\or digits    \n",
        "        if special_char_removal:\n",
        "            # insert spaces between special characters to isolate them    \n",
        "            special_char_pattern = re.compile(r'([{.(-)!}])')\n",
        "            doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
        "            doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
        "        # remove extra whitespace\n",
        "        doc = re.sub(' +', ' ', doc)\n",
        "        # remove stopwords\n",
        "        if stopword_removal:\n",
        "            doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
        "            \n",
        "        normalized_corpus.append(doc)\n",
        "    return normalized_corpus\n",
        "\n",
        "# pre-process text and store the same\n",
        "df['clean_text'] = normalize_corpus(df['full_text'])\n",
        "norm_corpus = list(df['clean_text'])\n",
        "\n",
        "# show a sample news article\n",
        "df.iloc[1][['full_text', 'clean_text']].to_dict()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clean_text': 'spookys jump scare mansion good game well sam pepper youtube account need play computersome extra pants pro scary hell fun adventure spooky forgot mention scary hellyou get pant brief wardrobe time consume bored con buy pant brief not download yet survive room cute terror break cuteness start fade run life unspeakable hideous shake writhe bowel house wait wait hunger meet long finally meet show flexible skin soak blood brave journey set beat impossible insane incorporeal [ horror free play cute first person singleplayer psychological horror indie adventure dark funny atmospheric action walk simulator survival survival horror anime gore comedy multiplayer illuminati ] lag studio lag studio',\n",
              " 'full_text': \"Spooky's Jump Scare Mansion. Best game, more better than Sam Pepper's YouTube account. 10/10What you'll need to play:A computerSome extra pants.Pros:Scary as hell.Fun.Adventure.Spooky.Did I forgot to mention that its scary as hell?You'll get more pants/briefs in your wardrobe.Time consuming if you're bored.Cons:Buying pants/briefs. You haven't downloaded it yet.. Can you survive 1000 rooms of cute terror? Or will you break once the cuteness starts to fade off and you're running for your life from the unspeakable hideous beings that shake and writhe in bowels of this house? They wait for you, they wait and hunger for meeting you. They long to finally meet you and show you how flexible your skin can be after it has soaked in blood. Will you brave this journey, will you set to beat the impossible, the insane, and the incorporeal?. ['Horror', 'Free to Play', 'Cute', 'First-Person', 'Singleplayer', 'Psychological Horror', 'Indie', 'Adventure', 'Dark', 'Funny', 'Atmospheric', 'Action', 'Walking Simulator', 'Survival', 'Survival Horror', 'Anime', 'Gore', 'Comedy', 'Multiplayer', 'Illuminati']. Lag Studios . Lag Studios \"}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcz2IfuvgK0y",
        "colab_type": "code",
        "outputId": "825e26b5-418b-4209-9c97-d65755948d55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "test['clean_text'] = normalize_corpus(test['full_text'])\n",
        "norm_corpus = list(test['clean_text'])\n",
        "\n",
        "# show a sample news article\n",
        "test.iloc[1][['full_text', 'clean_text']].to_dict()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clean_text': 'counter strike global offensive would not recommend get current state csgo hit rock bottom valve miss promise game change update lack effort combat terrible cheating problem bug game year still not fix cheating control past year playing cheating get bad bad point end play cheater almost every game valve implement new trust matchmaking system combat issue lackluster algorithm still somehow think put year gameplay hour people play brand new account make sense really not know still put effort play game anymore usually end regret guess wish could somehow fun use play game seem day long go counter strike global offensive cs go expand upon team base action gameplay pioneer launch year ago cs go feature new map character weapon game mode deliver update version classic cs content de_dust etc counter strike take gaming industry surprise unlikely mod become played online pc action game world almost immediately release august say doug lombardi valve past year continue one play game world headline competitive gaming tournament sell million unit worldwide across franchise cs go promise expand cs award win gameplay deliver gamer pc well next gen consoles mac [ fps multiplayer shooter action team base competitive tactical first person e sport pvp online co op military co op strategy war trading difficult realistic fast pace moddable ] valve valve hide path entertainment',\n",
              " 'full_text': 'Counter-Strike: Global Offensive. I would not recommend getting into this at its current state. CSGO has hit rock bottom with Valve\\'s missed promises of game changing updates and their lack of effort to combat the terrible cheating problem. Bugs have been in the game for years and still haven\\'t been fixed. Cheating is out of control. Over the past few years of playing, cheating has gotten worse and worse to the point now where I end up playing against a cheater almost every game. Valve implemented the new \"trust\" matchmaking system to combat some of these issues but its lackluster algorithm still somehow thinks putting me, with years of gameplay and 3,000+ hours, against people playing on brand new accounts makes sense. I really don\\'t know why I still put the effort to play this game anymore because it usually just ends up with me regretting it. I guess I just wish I could somehow have the fun I used to have playing this game but it seems those days are long gone.. Counter-Strike: Global Offensive (CS: GO) expands upon the team-based action gameplay that it pioneered when it was launched 19 years ago.CS: GO features new maps, characters, weapons, and game modes, and delivers updated versions of the classic CS content (de_dust2, etc.).\"Counter-Strike took the gaming industry by surprise when the unlikely MOD became the most played online PC action game in the world almost immediately after its release in August 1999,\" said Doug Lombardi at Valve. \"For the past 12 years, it has continued to be one of the most-played games in the world, headline competitive gaming tournaments and selling over 25 million units worldwide across the franchise. CS: GO promises to expand on CS\\' award-winning gameplay and deliver it to gamers on the PC as well as the next gen consoles and the Mac.\". [\\'FPS\\', \\'Multiplayer\\', \\'Shooter\\', \\'Action\\', \\'Team-Based\\', \\'Competitive\\', \\'Tactical\\', \\'First-Person\\', \\'e-sports\\', \\'PvP\\', \\'Online Co-Op\\', \\'Military\\', \\'Co-op\\', \\'Strategy\\', \\'War\\', \\'Trading\\', \\'Difficult\\', \\'Realistic\\', \\'Fast-Paced\\', \\'Moddable\\']. Valve . Valve, Hidden Path Entertainment '}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmij28Ki4Cpr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_all_Game=test['clean_text']\n",
        "train_all_Game=df[['clean_text','user_suggestion']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uY8QRnDTYYg",
        "colab_type": "code",
        "outputId": "eda86998-a7c0-48e8-c75f-8430ede0156e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "my_df = pd.read_csv('/content/Videogame_clean_train.csv')\n",
        "my_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>user_suggestion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spookys jump scare mansion scared hear creepy ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spookys jump scare mansion good game well sam ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spookys jump scare mansion littly iffy control...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spookys jump scare mansion great game fun colo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spookys jump scare mansion not many game cute ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text  user_suggestion\n",
              "0  spookys jump scare mansion scared hear creepy ...                1\n",
              "1  spookys jump scare mansion good game well sam ...                1\n",
              "2  spookys jump scare mansion littly iffy control...                1\n",
              "3  spookys jump scare mansion great game fun colo...                1\n",
              "4  spookys jump scare mansion not many game cute ...                1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6fyr0hcULY7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('/content/Videogame_clean_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsSXVphB7ve5",
        "colab_type": "code",
        "outputId": "c819ac4e-8559-4f0b-dd6e-283cab4f8a23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "my_df = pd.read_csv('/content/Videogame_clean_train.csv')\n",
        "test = pd.read_csv('/content/Videogame_clean_test.csv')\n",
        "my_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>user_suggestion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>spookys jump scare mansion scared hear creepy ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>spookys jump scare mansion good game well sam ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spookys jump scare mansion littly iffy control...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>spookys jump scare mansion great game fun colo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>spookys jump scare mansion not many game cute ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          clean_text  user_suggestion\n",
              "0  spookys jump scare mansion scared hear creepy ...                1\n",
              "1  spookys jump scare mansion good game well sam ...                1\n",
              "2  spookys jump scare mansion littly iffy control...                1\n",
              "3  spookys jump scare mansion great game fun colo...                1\n",
              "4  spookys jump scare mansion not many game cute ...                1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBU-mfMHTxux",
        "colab_type": "code",
        "outputId": "3398a3cc-f093-4338-a654-d9b3ff58b8de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "my_df.dropna(inplace=True)\n",
        "my_df.reset_index(drop=True,inplace=True)\n",
        "my_df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17494 entries, 0 to 17493\n",
            "Data columns (total 2 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   clean_text       17494 non-null  object\n",
            " 1   user_suggestion  17494 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 273.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RjDpAI0rT_sg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = my_df.clean_text\n",
        "y = my_df.user_suggestion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epqk7SL0T5Kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "SEED = 2000\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.02, random_state=SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Z-T4vnQUQxi",
        "colab_type": "code",
        "outputId": "11ea20ff-9417-4e04-ec5f-ccf9f734a954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Train set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_train),\n",
        "                                                                             (len(x_train[y_train == 0]) / (len(x_train)*1.))*100,\n",
        "                                                                            (len(x_train[y_train == 1]) / (len(x_train)*1.))*100))\n",
        "print(\"Validation set has total {0} entries with {1:.2f}% negative, {2:.2f}% positive\".format(len(x_validation),\n",
        "                                                                             (len(x_validation[y_validation == 0]) / (len(x_validation)*1.))*100,\n",
        "                                                                            (len(x_validation[y_validation == 1]) / (len(x_validation)*1.))*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train set has total 17144 entries with 43.02% negative, 56.98% positive\n",
            "Validation set has total 350 entries with 43.14% negative, 56.86% positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHyX8ZbtV4l4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from textblob import TextBlob\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzLKCSoQWNwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
        "    if len(x_test[y_test == 0]) / (len(x_test)*1.) > 0.5:\n",
        "        null_accuracy = len(x_test[y_test == 0]) / (len(x_test)*1.)\n",
        "    else:\n",
        "        null_accuracy = 1. - (len(x_test[y_test == 0]) / (len(x_test)*1.))\n",
        "    t0 = time()\n",
        "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
        "    y_pred = sentiment_fit.predict(x_test)\n",
        "    train_test_time = time() - t0\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print( \"null accuracy: {0:.2f}%\".format(null_accuracy*100))\n",
        "    print( \"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
        "    if accuracy > null_accuracy:\n",
        "        print(\"model is {0:.2f}% more accurate than null accuracy\".format((accuracy-null_accuracy)*100))\n",
        "    elif accuracy == null_accuracy:\n",
        "        print( \"model has the same accuracy with the null accuracy\")\n",
        "    else:\n",
        "        print( \"model is {0:.2f}% less accurate than null accuracy\".format((null_accuracy-accuracy)*100))\n",
        "    print( \"train and test time: {0:.2f}s\".format(train_test_time))\n",
        "    print( \"-\"*80)\n",
        "    return accuracy, train_test_time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdFH47pzW5Ah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cvec = CountVectorizer()\n",
        "lr = LogisticRegression()\n",
        "n_features = np.arange(10000,100001,10000)\n",
        "\n",
        "def nfeature_accuracy_checker(vectorizer=cvec, n_features=n_features, stop_words=None, ngram_range=(1, 1), classifier=lr):\n",
        "    result = []\n",
        "    print (classifier)\n",
        "    print( \"\\n\")\n",
        "    for n in n_features:\n",
        "        vectorizer.set_params(stop_words=stop_words, max_features=n, ngram_range=ngram_range)\n",
        "        checker_pipeline = Pipeline([\n",
        "            ('vectorizer', vectorizer),\n",
        "            ('classifier', classifier)\n",
        "        ])\n",
        "        print( \"Validation result for {} features\".format(n))\n",
        "        nfeature_accuracy,tt_time = accuracy_summary(checker_pipeline, x_train, y_train, x_validation, y_validation)\n",
        "        result.append((n,nfeature_accuracy,tt_time))\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prpuBfI3XO0_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tvec = TfidfVectorizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDCPHFl_XXdo",
        "colab_type": "code",
        "outputId": "e462d73e-326e-4fbe-8c70-a2ef83d37623",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%%time\n",
        "print( \"RESULT FOR TRIGRAM WITH STOP WORDS (Tfidf)\\n\")\n",
        "feature_result_tgt = nfeature_accuracy_checker(vectorizer=tvec,ngram_range=(1, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RESULT FOR TRIGRAM WITH STOP WORDS (Tfidf)\n",
            "\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "\n",
            "\n",
            "Validation result for 10000 features\n",
            "null accuracy: 56.86%\n",
            "accuracy score: 82.00%\n",
            "model is 25.14% more accurate than null accuracy\n",
            "train and test time: 22.30s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for 20000 features\n",
            "null accuracy: 56.86%\n",
            "accuracy score: 82.57%\n",
            "model is 25.71% more accurate than null accuracy\n",
            "train and test time: 22.43s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for 30000 features\n",
            "null accuracy: 56.86%\n",
            "accuracy score: 83.43%\n",
            "model is 26.57% more accurate than null accuracy\n",
            "train and test time: 22.52s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for 40000 features\n",
            "null accuracy: 56.86%\n",
            "accuracy score: 83.14%\n",
            "model is 26.29% more accurate than null accuracy\n",
            "train and test time: 25.20s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for 50000 features\n",
            "null accuracy: 56.86%\n",
            "accuracy score: 83.14%\n",
            "model is 26.29% more accurate than null accuracy\n",
            "train and test time: 23.32s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for 60000 features\n",
            "null accuracy: 56.86%\n",
            "accuracy score: 83.14%\n",
            "model is 26.29% more accurate than null accuracy\n",
            "train and test time: 26.72s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for 70000 features\n",
            "null accuracy: 56.86%\n",
            "accuracy score: 83.14%\n",
            "model is 26.29% more accurate than null accuracy\n",
            "train and test time: 26.12s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for 80000 features\n",
            "null accuracy: 56.86%\n",
            "accuracy score: 83.14%\n",
            "model is 26.29% more accurate than null accuracy\n",
            "train and test time: 24.56s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for 90000 features\n",
            "null accuracy: 56.86%\n",
            "accuracy score: 83.14%\n",
            "model is 26.29% more accurate than null accuracy\n",
            "train and test time: 25.00s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for 100000 features\n",
            "null accuracy: 56.86%\n",
            "accuracy score: 83.14%\n",
            "model is 26.29% more accurate than null accuracy\n",
            "train and test time: 25.08s\n",
            "--------------------------------------------------------------------------------\n",
            "CPU times: user 4min 6s, sys: 43 s, total: 4min 49s\n",
            "Wall time: 4min 3s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x7M9YbubiJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_pred = test['clean_text']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9kMTSubeZqvB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tvec = TfidfVectorizer(max_features=100000,ngram_range=(1, 3))\n",
        "x_train_tfidf = tvec.fit_transform(x)\n",
        "test_validation_tfidf = tvec.transform(test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s1ekbf-bI7d",
        "colab_type": "code",
        "outputId": "ffb29b93-bc5e-4470-acf5-58da60c03ff7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x_train_tfidf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<17494x100000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 10967353 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba2_RqsXba6d",
        "colab_type": "code",
        "outputId": "b321f2cf-f5bc-45d0-f9a9-f71a998e368a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_validation_tfidf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<8045x100000 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 2154306 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYpxgEwWduiz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "x_vectorizer = vectorizer.fit_transform(x)\n",
        "test_vectorizer = vectorizer.transform(test_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IELs55weHT4",
        "colab_type": "code",
        "outputId": "f394af26-2f63-4629-e8d1-ac905542fe58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "x_vectorizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<17494x46631 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 3332293 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETyYEyndeEiH",
        "colab_type": "code",
        "outputId": "009afe31-4328-4d88-d063-5d4f5ef00d33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_vectorizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<8045x46631 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 1392560 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lICmhFI2iYm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler,MaxAbsScaler\n",
        "maxscaler = MaxAbsScaler().fit(x_train_tfidf)\n",
        "X_train_MaxAbsScaler = maxscaler.transform(x_train_tfidf)\n",
        "test__MaxAbsScaler = maxscaler.transform(test_validation_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Df1hj7bazg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "tsvd = TruncatedSVD(100)\n",
        "train_tsvd = tsvd.fit_transform(X_train_MaxAbsScaler)\n",
        "test_tsvd = tsvd.fit_transform(test__MaxAbsScaler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUBseSArah-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x_train_tfidf,y, test_size = 0.3, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALxL69EZeKUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x_vectorizer,y, test_size = 0.3, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVTEQ2fRja0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(X_train_MaxAbsScaler,y, test_size = 0.3, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTpxlP74ZZJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(train_tsvd,y, test_size = 0.3, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBI71CP6aBBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztyfOeTEaPYC",
        "colab_type": "code",
        "outputId": "d0d21231-1f12-4c54-d99b-84e36f976ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "lr=LogisticRegression(penalty='l2',max_iter=1000,C=1,random_state=42)\n",
        "#Fitting the model for Bag of words\n",
        "lr_bow=lr.fit(xtrain,ytrain)\n",
        "print(lr_bow)\n",
        "lr_bow_predict=lr.predict(xtest)\n",
        "lr_bow_report=classification_report(ytest,lr_bow_predict)\n",
        "print(lr_bow_report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.83      0.84      2236\n",
            "           1       0.88      0.90      0.89      3013\n",
            "\n",
            "    accuracy                           0.87      5249\n",
            "   macro avg       0.87      0.86      0.87      5249\n",
            "weighted avg       0.87      0.87      0.87      5249\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01O0JOgiarHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predict_lr = lr_bow.predict(test__MaxAbsScaler)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l2-OAxleWcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predict_lr_vectorizer = lr_bow.predict(test_vectorizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8_tIIMEa9pm",
        "colab_type": "code",
        "outputId": "17983d7e-4892-4b09-dbca-3775f8f36f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_predict_lr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmfXb2Q5eiA5",
        "colab_type": "code",
        "outputId": "68e740f1-c3dd-454e-e3d2-a656c76c1815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_predict_lr_vectorizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISlgiJ6HbEkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(test_predict_lr).to_csv('test_all_predict_lr_maxabsscaling.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H90K16pRelYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(test_predict_lr_vectorizer).to_csv('test_predict_lr_vectorizer.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJg8p6efZvhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_selection import chi2\n",
        "chi2score = chi2(x_train_tfidf, y_train)[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzKgCfEufA8h",
        "colab_type": "code",
        "outputId": "6e77aaaa-5ae0-4b41-dac6-b66f0e0324b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "  from sklearn.ensemble import RandomForestClassifier\n",
        "  random_clf = RandomForestClassifier(max_depth=15, random_state=0)\n",
        "  random_clf.fit(xtrain,ytrain)\n",
        "  print(\"\\n**Random forest**\\n\")\n",
        "  \n",
        "  print('train accuracy',random_clf.score(xtrain,ytrain))\n",
        "  print('test accuracy',random_clf.score(xtest,ytest))\n",
        "  \n",
        "  y_pred = random_clf.predict(xtest)\n",
        "  \n",
        "  from sklearn.metrics import classification_report, confusion_matrix\n",
        "  print(\"classification report :  \\n \", classification_report(ytest, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "**Random forest**\n",
            "\n",
            "train accuracy 0.74822376480196\n",
            "test accuracy 0.7247094684701848\n",
            "classification report :  \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.45      0.58      2236\n",
            "           1       0.70      0.93      0.79      3013\n",
            "\n",
            "    accuracy                           0.72      5249\n",
            "   macro avg       0.76      0.69      0.69      5249\n",
            "weighted avg       0.75      0.72      0.70      5249\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jJ91QsodR4x",
        "colab_type": "code",
        "outputId": "d2c2e4f3-1c34-4c4e-8e6b-12d82acd5f7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dec_clf = DecisionTreeClassifier(random_state=0)\n",
        "dec_clf.fit(xtrain,ytrain)\n",
        "print(\"\\n**Random forest**\\n\")\n",
        "  \n",
        "print('train accuracy',dec_clf.score(xtrain,ytrain))\n",
        "print('test accuracy',dec_clf.score(xtest,ytest))\n",
        "  \n",
        "y_pred = dec_clf.predict(xtest)\n",
        "  \n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\"classification report :  \\n \", classification_report(ytest, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "**Random forest**\n",
            "\n",
            "train accuracy 0.9999183340138832\n",
            "test accuracy 0.7384263669270337\n",
            "classification report :  \n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.68      0.69      2236\n",
            "           1       0.77      0.78      0.77      3013\n",
            "\n",
            "    accuracy                           0.74      5249\n",
            "   macro avg       0.73      0.73      0.73      5249\n",
            "weighted avg       0.74      0.74      0.74      5249\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Wtrja9fix5",
        "colab_type": "code",
        "outputId": "7bb5c4b6-1282-4594-e2f8-352185f1b04e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        }
      },
      "source": [
        "mnb=MultinomialNB()\n",
        "#fitting the svm for bag of words\n",
        "mnb_bow=mnb.fit(xtrain,ytrain)\n",
        "print(mnb_bow)\n",
        "mnb_bow_predict=mnb.predict(xtest)\n",
        "mnb_bow_report=classification_report(ytest,mnb_bow_predict)\n",
        "print(mnb_bow_report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.74      0.69      2236\n",
            "           1       0.78      0.71      0.75      3013\n",
            "\n",
            "    accuracy                           0.72      5249\n",
            "   macro avg       0.72      0.72      0.72      5249\n",
            "weighted avg       0.73      0.72      0.72      5249\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqqyy53cf_0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_test_NB_tfidf = mnb_bow.predict(test_validation_tfidf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH6KZJj2gbXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame(pred_test_NB_tfidf).to_csv('pred_test_NB_tfidf.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYhrxwdSmKlr",
        "colab_type": "code",
        "outputId": "53dcf144-972f-4c4f-b5d8-cca6c7245263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "SVC_clf = SVC()\n",
        "SVC_clf.fit(xtrain, ytrain)\n",
        "SVC_clf_pred = SVC_clf.predict(xtest)\n",
        "print(classification_report(ytest,SVC_clf_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.59      0.65      2312\n",
            "           1       0.72      0.83      0.77      2937\n",
            "\n",
            "    accuracy                           0.72      5249\n",
            "   macro avg       0.72      0.71      0.71      5249\n",
            "weighted avg       0.72      0.72      0.72      5249\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcgExbonq7D_",
        "colab_type": "code",
        "outputId": "1cc980b9-ef96-4d55-b581-0122fce1a763",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "LinearSVC_clf = LinearSVC(random_state=0, tol=1e-5)\n",
        "LinearSVC_clf.fit(xtrain, ytrain)\n",
        "LinearSVC_clf_pred = LinearSVC_clf.predict(xtest)\n",
        "print(classification_report(ytest,SVC_clf_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.59      0.65      2312\n",
            "           1       0.72      0.83      0.77      2937\n",
            "\n",
            "    accuracy                           0.72      5249\n",
            "   macro avg       0.72      0.71      0.71      5249\n",
            "weighted avg       0.72      0.72      0.72      5249\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ony5RndUROni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost.sklearn import XGBClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWn4Upz1SYKh",
        "colab_type": "code",
        "outputId": "22979d50-8459-4556-f100-8e5c31618032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
        "xgb_model.fit(xtrain,ytrain)\n",
        "\n",
        "y_pred = xgb_model.predict(xtest)\n",
        "\n",
        "print(classification_report(ytest, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.70      0.76      2280\n",
            "           1       0.79      0.89      0.84      2969\n",
            "\n",
            "    accuracy                           0.81      5249\n",
            "   macro avg       0.81      0.79      0.80      5249\n",
            "weighted avg       0.81      0.81      0.80      5249\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdSo0yGOTEY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_test_xgb_tfidf = xgb_model.predict(test_validation_tfidf)\n",
        "pd.DataFrame(pred_test_xgb_tfidf).to_csv('pred_test_xgb_tfidf.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FANWmpKQq8oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm as lgbm\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YO5SYyj3nKpn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "params = {\n",
        "    'objective' :'binary',\n",
        "    'learning_rate' : 0.02,\n",
        "    'num_leaves' : 76,\n",
        "    'feature_fraction': 0.64, \n",
        "    'bagging_fraction': 0.8, \n",
        "    'bagging_freq':1,\n",
        "    'boosting_type' : 'gbdt',\n",
        "    'metric': 'binary_logloss'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeqUCzXHnQIv",
        "colab_type": "code",
        "outputId": "92d5e2b1-d4fa-4cbe-fc69-2ee99d369b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        }
      },
      "source": [
        "    d_train = lgbm.Dataset(xtrain,ytrain)\n",
        "    d_valid = lgbm.Dataset(xtest, ytest)\n",
        "    \n",
        "    # training with early stop\n",
        "    bst = lgbm.train(params, d_train, 5000, valid_sets=[d_valid], verbose_eval=50, early_stopping_rounds=100)\n",
        "    \n",
        "    # making prediciton for one column\n",
        "    \n",
        "    y_pred = np.round(bst.predict(xtest))\n",
        "    print(classification_report(ytest, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 100 rounds.\n",
            "[50]\tvalid_0's binary_logloss: 0.497919\n",
            "[100]\tvalid_0's binary_logloss: 0.43145\n",
            "[150]\tvalid_0's binary_logloss: 0.39568\n",
            "[200]\tvalid_0's binary_logloss: 0.372823\n",
            "[250]\tvalid_0's binary_logloss: 0.357476\n",
            "[300]\tvalid_0's binary_logloss: 0.346799\n",
            "[350]\tvalid_0's binary_logloss: 0.338685\n",
            "[400]\tvalid_0's binary_logloss: 0.333571\n",
            "[450]\tvalid_0's binary_logloss: 0.32931\n",
            "[500]\tvalid_0's binary_logloss: 0.326763\n",
            "[550]\tvalid_0's binary_logloss: 0.325306\n",
            "[600]\tvalid_0's binary_logloss: 0.324652\n",
            "[650]\tvalid_0's binary_logloss: 0.324005\n",
            "[700]\tvalid_0's binary_logloss: 0.323949\n",
            "[750]\tvalid_0's binary_logloss: 0.325037\n",
            "Early stopping, best iteration is:\n",
            "[688]\tvalid_0's binary_logloss: 0.323468\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.80      0.83      2274\n",
            "           1       0.86      0.90      0.88      2975\n",
            "\n",
            "    accuracy                           0.86      5249\n",
            "   macro avg       0.86      0.85      0.86      5249\n",
            "weighted avg       0.86      0.86      0.86      5249\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX9mFD5ssxCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_rounf = np.round(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xh7lBYTDs7r0",
        "colab_type": "code",
        "outputId": "98bd8a31-8397-47a1-9083-bb756c130c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred_rounf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1., 0., ..., 0., 1., 1.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRk7gCGEsjdN",
        "colab_type": "code",
        "outputId": "6479b7c7-2428-4b35-bb8b-8115cd5417f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "y_pred = bst.predict(xtest)\n",
        "print(classification_report(ytest, y_pred_rounf))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.78      0.80      2235\n",
            "           1       0.84      0.87      0.86      3014\n",
            "\n",
            "    accuracy                           0.83      5249\n",
            "   macro avg       0.83      0.83      0.83      5249\n",
            "weighted avg       0.83      0.83      0.83      5249\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NK755LmtHFQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predict_lgbm = np.round(bst.predict(test_validation_tfidf))\n",
        "pd.DataFrame(test_predict_lgbm).to_csv('test_predict_lgbm_tfid.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}